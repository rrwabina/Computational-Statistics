{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS321: Computational Statistics <br>\n",
    "\n",
    "##   Lecture: Metropolis-Hastings Algorithm\n",
    "\n",
    "University of Science and Technology of Southern Philippines <br>\n",
    "\n",
    "## Student Name: <code>Romen Samuel Wabina</code>\n",
    "\n",
    "Instructor: **Romen Samuel Wabina, MSc** <br>\n",
    "MSc Data Science and AI | Asian Institute of Technology <br>\n",
    "*ongoing* PhD Data Science (Healthcare and Clinical Informatics) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario 1 :\n",
      "Step 0 :\t Stage 3 -> Stage 4 (Transition Probability: 0.4 )\n",
      "Step 1 :\t Stage 4 -> Stage 5 (Transition Probability: 0.3 )\n",
      "Step 2 :\t Stage 5 -> Stage 5 (Transition Probability: 0.7 )\n",
      "Step 3 :\t Stage 5 -> Stage 5 (Transition Probability: 0.7 )\n",
      "Step 4 :\t Stage 5 -> Stage 5 (Transition Probability: 0.7 )\n",
      "Step 5 :\t Stage 5 -> Stage 5 (Transition Probability: 0.7 )\n",
      "Step 6 :\t Stage 5 -> CVD (Transition Probability: 0.2 )\n",
      "Step 7 :\t CVD -> CVD (Transition Probability: 0.8 )\n",
      "Step 8 :\t CVD -> CVD (Transition Probability: 0.8 )\n",
      "Step 9 :\t CVD -> CVD (Transition Probability: 0.8 )\n",
      "Step 10 :\t CVD -> DEATH (Transition Probability: 0.2 )\n",
      "Step 11 :\t DEATH\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Transition probabilities representing the Markov Chain\n",
    "transition_prob = {\n",
    "    'Stage 3': {'Stage 3': 0.5, 'Stage 4': 0.4, 'Stage 5': 0.1, 'CVD': 0.0, 'DEATH': 0.0},\n",
    "    'Stage 4': {'Stage 3': 0.0, 'Stage 4': 0.6, 'Stage 5': 0.3, 'CVD': 0.1, 'DEATH': 0.0},\n",
    "    'Stage 5': {'Stage 3': 0.0, 'Stage 4': 0.0, 'Stage 5': 0.7, 'CVD': 0.2, 'DEATH': 0.1},\n",
    "    'CVD':     {'Stage 3': 0.0, 'Stage 4': 0.0, 'Stage 5': 0.0, 'CVD': 0.8, 'DEATH': 0.2},\n",
    "    'DEATH':   {'Stage 3': 0.0, 'Stage 4': 0.0, 'Stage 5': 0.0, 'CVD': 0.0, 'DEATH': 1.0}\n",
    "}\n",
    "\n",
    "num_sequences = 1          # Number of sequences to generate\n",
    "initial_state = 'Stage 3'  # Starting from Stage 3\n",
    "\n",
    "# Loop over each sequence\n",
    "for sequence_num in range(num_sequences):\n",
    "    sequence = [initial_state]  # Store the states of the generated sequence\n",
    "    current_state = initial_state  # Set the current state to the initial state\n",
    "\n",
    "    # Generate the sequence until 'DEATH' state is reached\n",
    "    while current_state != 'DEATH':\n",
    "        # Randomly select the next state based on transition probabilities\n",
    "        next_state = np.random.choice(list(transition_prob[current_state].keys()), p=list(transition_prob[current_state].values()))\n",
    "        sequence.append(next_state)  # Append the next state to the sequence\n",
    "        current_state = next_state   # Update the current state\n",
    "\n",
    "    # Print the sequence label\n",
    "    print(\"Scenario\", sequence_num + 1, \":\")\n",
    "\n",
    "    # Iterate over each step in the sequence\n",
    "    for i, state in enumerate(sequence):\n",
    "        if i < len(sequence) - 1:  # Check if it's not the last step\n",
    "            next_state = sequence[i + 1]  # Get the next state\n",
    "            transition_prob_value = transition_prob[state][next_state]  # Get the transition probability\n",
    "            # Print the step, current state, next state, and transition probability\n",
    "            print(\"Step\", i, \":\\t\", state, \"->\", next_state, \"(Transition Probability:\", transition_prob_value, \")\")\n",
    "        else:  # Last step in the sequence\n",
    "            # Print the step and current state\n",
    "            print(\"Step\", i, \":\\t\", state)\n",
    "    print()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct Sampling\n",
    "\n",
    "Direct sampling, also known as direct Monte Carlo sampling or direct simulation, is a technique used in statistics and Monte Carlo methods to generate samples from a target distribution of interest. The goal of direct sampling is to obtain representative samples from a complex or high-dimensional distribution that may be challenging to sample from directly. In direct sampling, each sample is generated independently by drawing random values from the target distribution. The key idea is to use the properties of the target distribution, such as its probability density function (PDF), to guide the sampling process.\n",
    "\n",
    "The general steps involved in direct sampling are as follows:\n",
    "1. Define the target distribution: Specify the probability distribution from which you want to generate samples. This distribution may represent a population, a physical system, or any other phenomenon of interest.\n",
    "2. Determine the sampling method: Choose a suitable technique to sample from the target distribution. This choice depends on the specific characteristics of the distribution and the available information about it. Some common direct sampling methods include inverse transform sampling, acceptance-rejection sampling, and importance sampling.\n",
    "3. Generate independent samples: Using the selected sampling method, generate a series of independent samples from the target distribution. The number of samples generated depends on the desired sample size or the convergence criteria of the estimation problem at hand.\n",
    "4. Analyze the samples: Once the samples are generated, they can be used for various purposes, such as estimating population statistics, simulating system behavior, or conducting statistical inference.\n",
    "\n",
    "\n",
    "In MC estimation, we approximate an integral by the sample mean of a function of simulated random variables. In more mathematical terms,\n",
    "\n",
    "$$\\int p(x)\\ f(x)\\ dx = \\mathbb{E}_{p(x)} \\big[\\ f(x) \\big] \\approx \\frac{1}{N} \\sum_{n=1}^{N}f(x_n)$$\n",
    "\n",
    "where $x_n \\sim \\ p(x)$.\n",
    "\n",
    "A useful application of MC is probability estimation. In fact, we can cast a probability as an expectation using the indicator function. In our case, given that $A = \\{I \\ | \\ I > 275\\}$, we define $f(x)$ as\n",
    "\n",
    "$$f(x) = I_{A}(x)= \\begin{cases} \n",
    "      1 & I \\geq 275 \\\\\n",
    "      0 & I < 275 \n",
    "   \\end{cases}$$\n",
    "   \n",
    "Replacing in our equation above, we get\n",
    "\n",
    "$$\\int p(x) \\ f(x) \\ dx = \\int I(x)\\ p(x) \\ d(x) = \\int_{x \\in A} p(x)\\ d(x) \\approx \\frac{1}{N} \\sum_{n=1}^{N}I_{A}(x_n)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled States (First Sample): [0, 1, 1, 1, 3, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def monte_carlo_markov_chain(transition_matrix, initial_state, num_samples, num_steps):\n",
    "    samples = []\n",
    "    \n",
    "    for _ in range(num_samples):\n",
    "        current_state = initial_state\n",
    "        states = [current_state]\n",
    "\n",
    "        for _ in range(num_steps):\n",
    "            transition_probabilities = transition_matrix[current_state]\n",
    "\n",
    "            # Direct Sampling\n",
    "            next_state = np.random.choice(len(transition_probabilities), p = transition_probabilities)\n",
    "            current_state = next_state\n",
    "            states.append(current_state)\n",
    "\n",
    "            # Stop sampling if a terminal state (e.g., Death) is reached\n",
    "            if current_state == len(transition_matrix) - 1:\n",
    "                break\n",
    "\n",
    "        samples.append(states)\n",
    "    return samples\n",
    "\n",
    "# Transition matrix representing the Markov Chain\n",
    "transition_matrix = np.array([\n",
    "    [0.5, 0.4, 0.1, 0.0, 0.0],\n",
    "    [0.0, 0.6, 0.3, 0.1, 0.0],\n",
    "    [0.0, 0.0, 0.7, 0.2, 0.1],\n",
    "    [0.0, 0.0, 0.0, 0.8, 0.2],\n",
    "    [0.0, 0.0, 0.0, 0.0, 1.0]])\n",
    "\n",
    "initial_state = 0   # Starting from Stage 3\n",
    "num_samples = 10    # Number of Monte Carlo samples\n",
    "num_steps = 10      # Number of steps to sample\n",
    "\n",
    "# Perform Monte Carlo sampling with the Markov Chain\n",
    "sampled_states = monte_carlo_markov_chain(transition_matrix, initial_state, num_samples, num_steps)\n",
    "\n",
    "# Print the sampled states for the first sample\n",
    "print(\"Sampled States (First Sample):\", sampled_states[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient 0 with CKD Progression: \t {0, 1, 3, 4}\n",
      "Patient 1 with CKD Progression: \t {0, 1, 2, 4}\n",
      "Patient 2 with CKD Progression: \t {0, 1, 2}\n",
      "Patient 3 with CKD Progression: \t {0, 1, 3}\n",
      "Patient 4 with CKD Progression: \t {0, 2, 3}\n",
      "Patient 5 with CKD Progression: \t {0, 2, 4}\n",
      "Patient 6 with CKD Progression: \t {0, 1, 3, 4}\n",
      "Patient 7 with CKD Progression: \t {0, 1, 3}\n",
      "Patient 8 with CKD Progression: \t {0, 1, 2, 3}\n",
      "Patient 9 with CKD Progression: \t {0, 1, 2, 3}\n"
     ]
    }
   ],
   "source": [
    "for idx, state in enumerate(sampled_states):\n",
    "    print(f'Patient {idx} with CKD Progression: \\t {set(state)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the context of a Markov Chain model for chronic kidney disease progression, direct sampling is not inherently difficult because the Markov Chain allows for the direct generation of samples. The transition probabilities between different stages of the disease and other health states determine the probabilities of transitioning from one state to another. However, direct sampling have disadvantages:\n",
    "\n",
    "1. Direct sampling can become challenging in high-dimensional spaces due to the \"curse of dimensionality.\" Obtaining representative samples becomes computationally expensive or infeasible as the number of dimensions increases.\n",
    "2. In some cases, the distribution of CKD stages and associated risk factors may be analytically or computationally intractable, making direct sampling challenging. If the distributions cannot be easily parameterized or sampled from, alternative methods like importance sampling or MCMC techniques may be more suitable.\n",
    "3. Direct sampling can be computationally expensive, especially if the CKD model involves complex calculations, simulations, or computationally intensive algorithms. Sampling directly from a large dataset or running extensive simulations may not be feasible in real-time applications or when dealing with a massive amount of data.\n",
    "\n",
    "Direct sampling is particularly useful when the target distribution can be easily evaluated or sampled from directly. It is straightforward to implement and does not require additional steps or adjustments compared to more complex sampling techniques like Markov Chain Monte Carlo (MCMC). However, direct sampling may become impractical or inefficient when the target distribution is high-dimensional, has complex dependencies, or lacks an analytically tractable form. In such cases, advanced sampling methods like MCMC algorithms, including the Metropolis-Hastings algorithm or Gibbs sampling, are often employed to overcome these challenges."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importance Sampling\n",
    "\n",
    "Importance sampling is a Markov Chain Monte Carlo method for evaluating properties of a particular distribution, while only having samples generated from a different distribution than the distribution of interest. \n",
    "\n",
    "Importance sampling is a variance reduction technique that can be used in the Monte Carlo method. The idea behind importance sampling is that certain values of the input random variables in a simulation have more impact on the parameter being estimated than others. \n",
    "- If these \"important\" values are emphasized by sampling more frequently, then the estimator variance can be reduced. Hence, the basic methodology in importance sampling is to choose a distribution which \"encourages\" the important values.\n",
    "\n",
    "\n",
    "With importance sampling, we try to reduce the variance of our Monte-Carlo integral estimation by choosing a better distribution from which to simulate our random variables. It involves multiplying the integrand by 1 (usually dressed up in a “tricky fashion”) to yield an expectation of a quantity that varies less than the original integrand over the region of integration. Concretely,\n",
    "\n",
    "$$\\mathbb{E}_{p(x)} \\big[\\ f(x) \\big] = \\int f(x)\\ p(x)\\ dx = \\int f(x)\\ p(x)\\ \\frac{q(x)}{q(x)}\\ dx = \\int \\frac{p(x)}{q(x)}\\cdot f(x)\\ q(x)\\ dx = \\mathbb{E}_{q(x)}  \\big[\\ f(x)\\cdot \\frac{p(x)}{q(x)} \\big]$$\n",
    "\n",
    "Thus, the MC estimation of the expectation becomes:\n",
    "\n",
    "$$\\mathbb{E}_{q(x)}  \\big[\\ f(x)\\cdot \\frac{p(x)}{q(x)} \\big] \\approx \\frac{1}{N} \\sum_{n=1}^{N} w_n \\cdot f(x_n)$$\n",
    "\n",
    "where $w_n = \\dfrac{p(x_n)}{q(x_n)}$\n",
    "\n",
    "\n",
    "In importance sampling, the proposal distribution is a probability distribution used to generate samples during the sampling process. It serves as an approximation to the target distribution from which you want to estimate properties or calculate expectations. The proposal distribution should ideally have a similar shape or be closely related to the target distribution to ensure accurate importance sampling estimates. The primary purpose of the proposal distribution is to efficiently explore the space of possible samples and assign appropriate weights to each sample. The importance weights, which are the ratios of the target distribution's density to the proposal distribution's density, are used to adjust the contribution of each sample to the final estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importance_sampling_markov_chain(transition_matrix, proposal_matrix, initial_state, num_samples, num_steps):\n",
    "    samples = []\n",
    "    weights = []\n",
    "    \n",
    "    for _ in range(num_samples):\n",
    "        current_state = initial_state\n",
    "        states = [current_state]\n",
    "        weight = 1.0\n",
    "\n",
    "        for _ in range(num_steps):\n",
    "            transition_probabilities = transition_matrix[current_state]\n",
    "            proposal_probabilities   = proposal_matrix[current_state]\n",
    "            \n",
    "            # Sample the next state using the proposal distribution\n",
    "            next_state = np.random.choice(len(proposal_probabilities), p = proposal_probabilities)\n",
    "            \n",
    "            # Calculate the weight using the importance sampling ratio\n",
    "            weight *= transition_probabilities[next_state] / proposal_probabilities[next_state]\n",
    "            \n",
    "            current_state = next_state\n",
    "            states.append(current_state)\n",
    "\n",
    "            # Stop sampling if a terminal state (e.g., Death) is reached\n",
    "            if current_state == len(transition_matrix) - 1:\n",
    "                break\n",
    "        \n",
    "        samples.append(states)\n",
    "        weights.append(weight)\n",
    "    \n",
    "    # Normalize the weights\n",
    "    weights /= np.sum(weights)\n",
    "    \n",
    "    return samples, weights\n",
    "\n",
    "# Target distribution\n",
    "# Transition matrix representing the Markov Chain\n",
    "transition_matrix = np.array([\n",
    "    [0.5, 0.4, 0.1, 0.0, 0.0],\n",
    "    [0.0, 0.6, 0.3, 0.1, 0.0],\n",
    "    [0.0, 0.0, 0.7, 0.2, 0.1],\n",
    "    [0.0, 0.0, 0.0, 0.8, 0.2],\n",
    "    [0.0, 0.0, 0.0, 0.0, 1.0]\n",
    "])\n",
    "\n",
    "# Proposal matrix representing the proposal distribution (can be different from the transition matrix)\n",
    "# The proposal distribution is a probability distribution used to generate samples during the sampling \n",
    "# process. It serves as an approximation to the target distribution from which you want to estimate \n",
    "# properties or calculate expectations. The proposal distribution should ideally have a similar shape \n",
    "# or be closely related to the target distribution to ensure accurate importance sampling estimates.\n",
    "proposal_matrix = np.array([\n",
    "    [0.3, 0.3, 0.2, 0.1, 0.1],\n",
    "    [0.1, 0.5, 0.2, 0.1, 0.1],\n",
    "    [0.0, 0.1, 0.6, 0.2, 0.1],\n",
    "    [0.0, 0.0, 0.1, 0.6, 0.3],\n",
    "    [0.0, 0.0, 0.0, 0.0, 1.0]\n",
    "])\n",
    "\n",
    "initial_state = 0  # Starting from Stage 3\n",
    "num_samples = 10   # Number of importance samples\n",
    "num_steps = 10     # Number of steps to sample\n",
    "\n",
    "# Perform importance sampling with the Markov Chain\n",
    "sampled_states, importance_weights = importance_sampling_markov_chain(\n",
    "    transition_matrix, proposal_matrix, initial_state, num_samples, num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient 0 with CKD Progression: \t {0, 2, 3}\n",
      "Patient 1 with CKD Progression: \t {0, 3, 4}\n",
      "Patient 2 with CKD Progression: \t {0, 2, 3, 4}\n",
      "Patient 3 with CKD Progression: \t {0, 3, 4}\n",
      "Patient 4 with CKD Progression: \t {0, 1, 2, 4}\n",
      "Patient 5 with CKD Progression: \t {0, 3, 4}\n",
      "Patient 6 with CKD Progression: \t {0, 2}\n",
      "Patient 7 with CKD Progression: \t {0, 1, 2, 4}\n",
      "Patient 8 with CKD Progression: \t {0, 1, 2, 4}\n",
      "Patient 9 with CKD Progression: \t {0, 2, 4}\n"
     ]
    }
   ],
   "source": [
    "for idx, state in enumerate(sampled_states):\n",
    "    print(f'Patient {idx} with CKD Progression: \\t {set(state)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metropolis-Hastings Algorithm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In statistics and statistical physics, the Metropolis–Hastings algorithm is a Markov chain Monte Carlo (MCMC) method for obtaining a sequence of random samples from a probability distribution from which direct sampling is difficult. \n",
    "\n",
    "**Objective:** In the Metropolis-Hastings algorithm, the goal is to generate a Markov Chain that samples from a target distribution, which may be difficult to sample directly. The algorithm achieves this by using a proposal distribution to generate candidate states and then accepting or rejecting these candidates based on their acceptance probability.\n",
    "\n",
    "Metropolis-Hastings algorithm requires the calculation of an acceptance probability. The acceptance probability is used to determine whether to accept or reject a proposed state transition during the sampling process. The acceptance probability is calculated as the ratio of the target distribution's density evaluated at the proposed state to the target distribution's density evaluated at the current state. The ratio is multiplied by a term that accounts for the proposal distribution's symmetry. The acceptance probability is defined as:\n",
    "\n",
    "$$ \\text{Acceptance Probability} = \\min(1, \\frac{{\\text{{target\\_density\\_proposed}}}}{{\\text{{target\\_density\\_current}}}} \\cdot \\frac{{\\text{{proposal\\_density\\_current}}}}{{\\text{{proposal\\_density\\_proposed}}}})$$\n",
    "\n",
    "\n",
    "The acceptance probability ensures that the Markov Chain converges to the desired target distribution by accepting candidate states that improve the match with the target distribution and occasionally accepting states that decrease the match. This trade-off allows the algorithm to explore the state space and sample from the target distribution effectively. The acceptance probability acts as a balancing factor, ensuring that the Markov Chain explores regions of the state space with higher probabilities while allowing for occasional exploration of lower probability regions. It helps to avoid getting stuck in local optima and promotes convergence to the desired target distribution.\n",
    "\n",
    "The acceptance or rejection of a proposed state transition is determined by comparing an acceptance ratio (or acceptance probability) to a randomly generated value. The accept-reject criterion can be summarized as follows:\n",
    "1. Generate a candidate state transition from the current state using a proposal distribution.\n",
    "2. Calculate the acceptance ratio, which is the ratio of the target distribution's density evaluated at the proposed state to the target distribution's density evaluated at the current state. This ratio is multiplied by a term that accounts for the proposal distribution's symmetry.\n",
    "3. Generate a random value, typically from a uniform distribution between 0 and 1.\n",
    "4. **If the acceptance ratio is greater than or equal to the random value (typical: uniform distribution), accept the proposed state transition. Otherwise, reject it and retain the current state.**\n",
    "\n",
    "\n",
    "The code below implements the Metropolis-Hastings algorithm for sampling from the Markov Chain. Starting from the initial state, the algorithm proposes new states based on the transition probabilities and decides whether to accept or reject the proposed state based on an acceptance probability. The process is repeated for the desired number of samples and steps.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient 0 with CKD Progression: \t {0, 1}\n",
      "Patient 1 with CKD Progression: \t {1, 2}\n",
      "Patient 2 with CKD Progression: \t {2}\n",
      "Patient 3 with CKD Progression: \t {2}\n",
      "Patient 4 with CKD Progression: \t {2}\n",
      "Patient 5 with CKD Progression: \t {2, 3}\n",
      "Patient 6 with CKD Progression: \t {3}\n",
      "Patient 7 with CKD Progression: \t {3}\n",
      "Patient 8 with CKD Progression: \t {3}\n",
      "Patient 9 with CKD Progression: \t {3}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def metropolis_hastings_markov_chain(transition_matrix, initial_state, num_samples, num_steps):\n",
    "    samples = []\n",
    "    \n",
    "    current_state = initial_state\n",
    "    for _ in range(num_samples):\n",
    "        states = [current_state]\n",
    "\n",
    "        for _ in range(num_steps):\n",
    "            transition_probabilities = transition_matrix[current_state]\n",
    "            \n",
    "            # Propose a new state based on the transition probabilities\n",
    "            next_state = np.random.choice(len(transition_probabilities), p=transition_probabilities)\n",
    "            \n",
    "            # Calculate the acceptance probability\n",
    "            # weight from the importance sampling\n",
    "            acceptance_prob = min(1, transition_probabilities[next_state] / transition_probabilities[current_state])\n",
    "            \n",
    "            # Use criteria \n",
    "            # Accept or reject the proposed state based on the acceptance probability\n",
    "            # Uniform or Poisson\n",
    "            if np.random.uniform() < acceptance_prob:\n",
    "                current_state = next_state\n",
    "            \n",
    "            states.append(current_state)\n",
    "\n",
    "            # Stop sampling if a terminal state (e.g., Death) is reached\n",
    "            if current_state == len(transition_matrix) - 1:\n",
    "                break\n",
    "        \n",
    "        samples.append(states)\n",
    "    \n",
    "    return samples\n",
    "\n",
    "# Transition matrix representing the Markov Chain\n",
    "transition_matrix = np.array([\n",
    "    [0.5, 0.4, 0.1, 0.0, 0.0],\n",
    "    [0.0, 0.6, 0.3, 0.1, 0.0],\n",
    "    [0.0, 0.0, 0.7, 0.2, 0.1],\n",
    "    [0.0, 0.0, 0.0, 0.8, 0.2],\n",
    "    [0.0, 0.0, 0.0, 0.0, 1.0]\n",
    "])\n",
    "\n",
    "initial_state = 0  # Starting from Stage 3\n",
    "num_samples   = 10 # Number of Metropolis-Hastings samples\n",
    "num_steps     = 5  # Number of steps to sample\n",
    "\n",
    "# Perform Metropolis-Hastings sampling with the Markov Chain\n",
    "sampled_states = metropolis_hastings_markov_chain(transition_matrix, initial_state, num_samples, num_steps)\n",
    "\n",
    "for idx, state in enumerate(sampled_states):\n",
    "    print(f'Patient {idx} with CKD Progression: \\t {set(state)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By comparing the acceptance ratio to a random value, the Metropolis-Hastings algorithm balances exploration and exploitation. It allows for occasional acceptance of state transitions that decrease the match with the target distribution, which helps the algorithm explore the state space and avoid getting stuck in local optima. The accept-reject criterion plays a crucial role in the algorithm's convergence to the desired target distribution and ensures that the Markov Chain generated by the algorithm approximates the target distribution effectively."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Implementation: Metropolis-Hastings Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importance Sampling:\n",
      "Estimated Mean: 4.815660868077247\n",
      "\n",
      "Metropolis-Hastings:\n",
      "Estimated Mean: 4.984573440505409\n",
      "Acceptance Ratio: 0.614909090909091\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def target_distribution(x):\n",
    "    \"\"\"Target distribution: Gaussian with mean 5 and standard deviation 2.\"\"\"\n",
    "    return np.exp(-(x - 5) ** 2 / 8) / np.sqrt(8 * np.pi)\n",
    "\n",
    "def proposal_distribution():\n",
    "    \"\"\"Proposal distribution: Uniform distribution between 0 and 10.\"\"\"\n",
    "    return np.random.uniform(0, 10)\n",
    "\n",
    "def importance_sampling(n_samples):\n",
    "    \"\"\"Implementation of Importance Sampling.\"\"\"\n",
    "    samples = np.zeros(n_samples)\n",
    "    weights = np.zeros(n_samples)\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        sample = proposal_distribution()\n",
    "        weight = target_distribution(sample) / proposal_distribution()\n",
    "        samples[i] = sample\n",
    "        weights[i] = weight\n",
    "\n",
    "    weights /= np.sum(weights)  # Normalize the weights\n",
    "    estimated_mean = np.sum(samples * weights)\n",
    "\n",
    "    return estimated_mean\n",
    "\n",
    "def metropolis_hastings(n_samples, burn_in=1000):\n",
    "    \"\"\"Implementation of Metropolis-Hastings.\"\"\"\n",
    "    samples = np.zeros(n_samples + burn_in)\n",
    "    accepted = 0\n",
    "    current_sample = proposal_distribution()\n",
    "\n",
    "    for i in range(n_samples + burn_in):\n",
    "        proposal = proposal_distribution()\n",
    "        acceptance_prob = min(1, target_distribution(proposal) / target_distribution(current_sample))\n",
    "\n",
    "        if np.random.rand() < acceptance_prob:\n",
    "            current_sample = proposal\n",
    "            accepted += 1\n",
    "\n",
    "        samples[i] = current_sample\n",
    "\n",
    "    samples = samples[burn_in:]\n",
    "    estimated_mean = np.mean(samples)\n",
    "\n",
    "    return estimated_mean, accepted / (n_samples + burn_in)\n",
    "\n",
    "# Testing the implementations\n",
    "np.random.seed(42)\n",
    "n_samples = 10000\n",
    "\n",
    "# Importance Sampling\n",
    "estimated_mean_importance = importance_sampling(n_samples)\n",
    "print(\"Importance Sampling:\")\n",
    "print(\"Estimated Mean:\", estimated_mean_importance)\n",
    "\n",
    "# Metropolis-Hastings\n",
    "estimated_mean_mh, acceptance_ratio = metropolis_hastings(n_samples)\n",
    "print(\"\\nMetropolis-Hastings:\")\n",
    "print(\"Estimated Mean:\", estimated_mean_mh)\n",
    "print(\"Acceptance Ratio:\", acceptance_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def importance_sampling_markov_chain(transition_matrix, pdf_func, initial_state, num_samples, num_steps):\n",
    "    samples = []\n",
    "    weights = []\n",
    "    \n",
    "    for _ in range(num_samples):\n",
    "        current_state = initial_state\n",
    "        states = [current_state]\n",
    "        weight = 1.0\n",
    "\n",
    "        for _ in range(num_steps):\n",
    "            transition_probabilities = transition_matrix[current_state]\n",
    "            \n",
    "            # Generate a sample from the proposal distribution using the given PDF\n",
    "            proposal_probabilities = pdf_func(current_state)\n",
    "            next_state = np.random.choice(len(proposal_probabilities), p=proposal_probabilities)\n",
    "            \n",
    "            # Calculate the weight using the importance sampling ratio\n",
    "            weight *= transition_probabilities[next_state] / proposal_probabilities[next_state]\n",
    "            \n",
    "            current_state = next_state\n",
    "            states.append(current_state)\n",
    "\n",
    "            # Stop sampling if a terminal state (e.g., Death) is reached\n",
    "            if current_state == len(transition_matrix) - 1:\n",
    "                break\n",
    "        \n",
    "        samples.append(states)\n",
    "        weights.append(weight)\n",
    "    \n",
    "    # Normalize the weights\n",
    "    weights /= np.sum(weights)\n",
    "    \n",
    "    return samples, weights\n",
    "\n",
    "# Transition matrix representing the Markov Chain\n",
    "transition_matrix = np.array([\n",
    "    [0.5, 0.4, 0.1, 0.0, 0.0],\n",
    "    [0.0, 0.6, 0.3, 0.1, 0.0],\n",
    "    [0.0, 0.0, 0.7, 0.2, 0.1],\n",
    "    [0.0, 0.0, 0.0, 0.8, 0.2],\n",
    "    [0.0, 0.0, 0.0, 0.0, 1.0]\n",
    "])\n",
    "\n",
    "initial_state = 0  # Starting from Stage 3\n",
    "num_samples = 1000  # Number of importance samples\n",
    "num_steps = 10  # Number of steps to sample\n",
    "\n",
    "# Define the proposal probability density function (PDF)\n",
    "def proposal_pdf(state):\n",
    "    # Example: Uniform distribution as the proposal PDF\n",
    "    num_states = len(transition_matrix)\n",
    "    probabilities = np.full(num_states, 1/num_states)\n",
    "    return probabilities\n",
    "\n",
    "# Perform importance sampling with the Markov Chain\n",
    "sampled_states, importance_weights = importance_sampling_markov_chain(\n",
    "    transition_matrix, proposal_pdf, initial_state, num_samples, num_steps\n",
    ")\n",
    "\n",
    "# Print the sampled states and their corresponding importance weights for the first sample\n",
    "print(\"Sampled States (First Sample):\", sampled_states[0])\n",
    "print(\"Importance Weights (First Sample):\", importance_weights[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
