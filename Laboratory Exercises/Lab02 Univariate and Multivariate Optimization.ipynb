{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS321: Computational Statistics <br>\n",
    "\n",
    "##   Laboratory Exercise: Univariate (Secant Method) and Multivariate Optimization (Introduction)\n",
    "\n",
    "University of Science and Technology of Southern Philippines <br>\n",
    "\n",
    "## Student Name: <code>Student Name</code>\n",
    "\n",
    "\n",
    "Instructor: **Romen Samuel Wabina, MSc** <br>\n",
    "MSc Data Science and AI | Asian Institute of Technology <br>\n",
    "*ongoing* PhD Data Science (Healthcare and Clinical Informatics) \n",
    "\n",
    "\n",
    "### Instructions\n",
    "- Please submit this laboratory exercise as a **Jupyter Notebook file** <code>.ipynb</code> via email <code>romensamuelrodis.wab@student.mahidol.edu</code>\n",
    "- Always remember: I use GPTZero "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Optimization: Secant Method\n",
    "\n",
    "The updating increment for Newton’s method relies on the second derivative, $g''(x(t))$. Hence, the Newton's method uses a succession of roots through tangent lines to better approximate a root of a function $f$. However, calculating this derivative is difficult, it might be replaced by the discrete-difference approximation \n",
    "$$ \\frac{[g'(x^{(t)}) - g'(x^{(t−1)})]}{(x^{(t)} − x^{(t−1)})} $$\n",
    "The result is the \\textbf{secant method}, which has the updating equation\n",
    "$$ x^{(t+1)} = x^{(t)} - g'(x^{(t)}) \\frac{x^{(t)}-x^{(t-1)}}{g'(x^{(t)})-g'(x^{(t-1)})} $$\n",
    "for $t \\leq 1$. The Secant Method requires two starting points, $x^{(0)}$ and $x^{(1)}$.\n",
    "\n",
    "\n",
    "The Secant method is an approximation of the Newton-Raphson method. Instead of using the current value of $x$ to figure out the next value of $x$, we use the current and previous value of $x$ to figure out the next value of $x$. We use the Secant Method when the function's derivative is difficult to obtain."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Secant Method\n",
    "\n",
    "Suppose we want to find a root of the function $f(x) = x^3 - 3x + 1$ using the secant method. Let $x_0 = 1$ and $x_1 = 2$ be our initial guesses. Then the secant method iteration formula is:\n",
    "\n",
    "$$x_{n+1} = x_n - \\frac{f(x_n)(x_n - x_{n-1})}{f(x_n) - f(x_{n-1})}$$\n",
    "\n",
    "for $n = 1,2,\\ldots,10$. To calculate the derivative $f'(x)$, we can use the power rule:\n",
    "\n",
    "$$f'(x) = 3x^2 - 3$$\n",
    "\n",
    "To use the secant method, we start with two initial guesses, $x_0$ and $x_1$, and then use the formula:\n",
    "\n",
    "$$ x_{n+1} = x_n - \\frac{f(x_n) \\cdot (x_n - x_{n-1})}{f(x_n) - f(x_{n-1})} $$\n",
    "\n",
    "We can use this formula to find the root of the function $f(x) = x^3 - 3x + 1$ with initial guesses $x_0 = 1$ and $x_1 = 2$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: \t 0.7222222222222223\n",
      "Iteration 2: \t 0.5918367346938775\n",
      "Iteration 3: \t 0.4521138912855911\n",
      "Iteration 4: \t 0.4159624650710387\n",
      "Iteration 5: \t 0.40863810283636876\n",
      "Iteration 6: \t 0.40825193717576524\n",
      "Iteration 7: \t 0.4082482922040402\n",
      "Iteration 8: \t 0.4082482904638708\n",
      "Iteration 9: \t 0.408248290463863\n",
      "Iteration 10: \t 0.408248290463863\n",
      "Secant's method local optima: x =  0.408248290463863\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import math \n",
    "\n",
    "def secant_method(f, x0, x1, iterations):\n",
    "    for i in range(iterations):\n",
    "        x2 = x1 - f(x1) * (x1 - x0) / float(f(x1) - f(x0))\n",
    "        \n",
    "        # Updating\n",
    "        x0, x1 = x1, x2\n",
    "        print(f'Iteration {i + 1}: \\t {x2}')\n",
    "    return x2\n",
    "\n",
    "def f_example(x):\n",
    "    return (4 * x ** 2) - (10 * x ** 2) + 1\n",
    "\n",
    "root = secant_method(f_example, 1, 2, 10)\n",
    "print(\"Secant's method local optima: x = \", root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: \t 1.6666666666666667\n",
      "Iteration 2: \t 1.548611111111111\n",
      "Iteration 3: \t 1.5323901618653801\n",
      "Iteration 4: \t 1.5320889893972243\n",
      "Newton's method local optima: x =  1.532088886237968\n"
     ]
    }
   ],
   "source": [
    "APPROX = 2\n",
    "TOL = 10**-5\n",
    "N = 10\n",
    "\n",
    "def f(x):\n",
    "    return math.pow(x, 3) - 3*x + 1\n",
    "\n",
    "def fprime(x):\n",
    "    return 3*math.pow(x, 2) - 3\n",
    "\n",
    "def newtons(approx, tol, n):\n",
    "    p0 = approx\n",
    "    for i in range(0, n):\n",
    "        p = p0 - (f(p0)/fprime(p0)) \n",
    "        if abs(p - p0) < tol:\n",
    "            return p\n",
    "        print(f'Iteration {i + 1}: \\t {p}')\n",
    "        p0 = p\n",
    "    return \"The method failed after {} iterations\".format(n)\n",
    "\n",
    "output = newtons(APPROX, TOL, N)\n",
    "print(\"Newton's method local optima: x = \", output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <code>Question 1</code>: Modify the function <code>secant_method</code> by adding the tolerance value as a parameter in the function. Use the function to evaluate whether its number of iterations has decreased. \n",
    "### <code>Question 2</code>: Evaluate the following equations on Secant method at 10 iterations using your modified Python function.\n",
    "- $f(x) = x^3 - x - 1$ at initial values $x_0 = 1$ and $x_1 = 2$.\n",
    "- $f(x) = \\cos{x} + 2\\sin{x} + x^2$ at initial values $x_0 = 0.001$ and $x_1 = 0.001$.\n",
    "\n",
    "\n",
    "### <code>Question 3</code>: Evaluate the following equations on Secant and Newton's method at 10 iterations. Create a function that prints the local optima of both methods and measure their difference. You can use the functions above. \n",
    "- $f(x) = x^2 - 2$ where $x_0 = 2$ as the initial guess for Newton's Method while $x_0 = 3$ and $x_1 = 2$ for the Secant Method\n",
    "- $f(x) = x^3 - 7x^2 + 8x - 3$ where $x_0 = 0.45$ as the initial guess for Newton's method while $x_0 = 1$ and $x_1 = 0.45$ for the Secant Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newton's method local optima: \t1.4142135623730951\n",
      "Secant method local optima:   \t1.414213562373095\n",
      "Difference: \t\t\t2.220446049250313e-16\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Put code here\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Optimization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify that $f(x, y) = x^2 + y^2$ has only one critical point, a minimum at the origin.\n",
    "- First, we have $f_x = 2x$ and $f_y = 2y$. Since they are both defined everywhere, we need only find where they are both zero.\n",
    "- Setting both partial derivatives equal to zero yields $x = 0$ and $y = 0$, so the only critical point is $(0, 0)$.\n",
    "- To classify the critical points, we compute $f_{xx} = 2$, $f_{xy} = 0$, and $f_{yy} = 2$. Then $D = 2 \\cdot 2 − 0^2 = 4$.\n",
    "- So, by the classification test, since $D > 0$ and $f_{xx} > 0$ at $(0, 0)$, we see that $(0, 0)$ is a **local minimum**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2*x, 2*y]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({x: 0, y: 0},\n",
       " array([[2., 0.],\n",
       "        [0., 2.]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sympy\n",
    "\n",
    "def get_critical_points(f, variables):\n",
    "    df = [sympy.diff(f, x) for x in variables]\n",
    "    print(df) #Partial derivative\n",
    "\n",
    "\n",
    "    H = np.array([[sympy.diff(df[i], x) for x in variables] for i in range(len(variables))])\n",
    "    # Hessian matrix\n",
    "    H = H.astype('float')\n",
    "\n",
    "    # Determine the critical points\n",
    "    crit_points = sympy.solve(df, variables)\n",
    "    return crit_points, H\n",
    "\n",
    "\n",
    "\n",
    "x, y = sympy.symbols('x, y')\n",
    "f = x**2 + y**2\n",
    "\n",
    "critical_points = get_critical_points(f, [x, y])\n",
    "critical_points\n",
    "\n",
    "\n",
    "# Hint to solve Q4: \n",
    "# Find the determinant using H\n",
    "# Use the criteria of the second derivative test\n",
    "#   if D > 0 and fxx > 0:\n",
    "#       return 'local minima'\n",
    "#   elif D>0 and fxx < 0:\n",
    "#       return 'local maxima'\n",
    "#   else:\n",
    "#       return 'Inconclusive'\n",
    "# Put all of this in a Python function\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>Question 4</code>Using the function <code>get_critical_points</code>, evaluate the following functions below by classifying the critical points whether they are local minima, local maxima, saddle points, or the function is inconclusive. You can create a Python function to solve this.\n",
    "- $f(x,y) = x^2+2xy+4y^2+5x-6y$\n",
    "- $f(x,y) = -x^2 - y^2$\n",
    "- $f(a, b) = a^2 + 3a^2 - 9a + b^2 - 12b$\n",
    "- $f(r, s) = 3rs - r^2 - s^2$\n",
    "- $f(c, d) = x^2 + y^2 + 2x + 6y$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
